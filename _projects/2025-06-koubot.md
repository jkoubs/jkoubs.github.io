---
title: '<em>KouBot</em>: Autonomous Mecanum-Wheeled Robot'
subtitle: 'Lightweight, Dockerized System for SLAM and Indoor Navigation'
featured_image: 'images/projects/2025-06-koubot/4-AN_x5.gif'
date: 2025-06-29
---

## Overview

***KouBot*** is a mecanum-wheeled indoor robot designed for autonomous navigation using ROS 2. It runs entirely in Docker on a Raspberry Pi 4B and features holonomic movement, SLAM, and real-time navigation for robust indoor autonomy.

![teleop](/images/projects/2025-06-koubot/0-teleop_cropped.gif)


### Goal

Design and build an affordable, ROS 2-based indoor robot with full autonomous navigation capabilities, leveraging Docker for reproducibility and portability.

### Key Features

- Mecanum-wheel drive for omnidirectional movement.
- ROS 2 nodes launched fully via Docker on a Raspberry Pi 4B.
- Real-time SLAM and autonomous navigation.
- Modular sensor integration (LiDAR, IMU).

## Technical Approach

### Hardware

- **Base:** Mecanum-wheeled chassis.
- **Controller & Motor Driver:** Arduino Mega 256 and Dual L298N H-Bridge modules.
- **Sensors:** 360Â° LiDAR, MPU9250 IMU.
- **Compute:** Raspberry Pi 4B (4GB).

### Software

- **Framework:** ROS 2 Humble.
- **Deployment:** Dockerized ROS 2 environment.
- **Simulation:** Gazebo.

### Subsystems

- SLAM mapping, autonomous navigation.
- Serial communication with Arduino motor controller.
- Sensor fusion for localization.


### Docker Integration

All ROS 2 packages and launch files are containerized, allowing isolated, consistent development environments and simplifying deployment on the Raspberry Pi.


## Results

### Teleoperation using PS4 Remote

![teleop](/images/projects/2025-06-koubot/1-teleop.gif)

*KouBot* supports manual control through a Bluetooth-connected PS4 controller, allowing for smooth and precise holonomic movement in all directions. This setup was essential for early testing, calibration, and validating motor functionality before implementing full autonomy.

### SLAM

![slam](/images/projects/2025-06-koubot/2-mapping_x5.gif)

Using SLAM Toolbox, *KouBot* was able to construct accurate 2D maps of its environment in real time. 

Here is the resulting map:

<!-- ![slam](/images/projects/2025-06-koubot/map.png) -->
<img src="/images/projects/2025-06-koubot/map.png" alt="SLAM map" class="slam-map-small" />


### Localization

![localization](/images/projects/2025-06-koubot/3-localization_x5.gif)

*KouBot* currently performs localization using LiDAR-based scan matching. In the future, IMU data will be fused with LiDAR-derived odometry using an Extended Kalman Filter (EKF) to enhance robustness and accuracy.

### Autonomous Navigation

![AN](/images/projects/2025-06-koubot/4-AN_x5.gif)

*KouBot* uses the ROS 2 Nav2 stack to navigate point-to-point, avoiding obstacles and reaching goals with high precision.

## Next Steps

While *KouBot* has proven its core SLAM and navigation capabilities, future improvements will focus on:

- Integrating full-state localization using an Extended Kalman Filter (EKF) to fuse LiDAR and IMU data.
- Planning to integrate a depth camera (OAK-D) for object detection and image processing experiments.
- Refining the motion controller with feedback from wheel encoders.

## GitHub Repository

[Explore the Project on GitHub](https://github.com/jkoubs/KouBot-ROS2/tree/master)
